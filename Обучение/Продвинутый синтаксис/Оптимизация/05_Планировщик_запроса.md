# Планировщик запросов

**Планировщик запросов** (оптимизатор) в PostgreSQL — это компонент, который анализирует SQL-запросы и генерирует наиболее эффективный план выполнения. Задача планировщика — выбрать план, который, как ожидается, будет выполняться быстрее всего.  

Чтобы получить результаты запроса, PostgreSQL выполняет следующие
шаги:  
-  компилирует и преобразует инструкцию SQL в выражение, состоящее
из логических операций высокого уровня, называемое логический план;  
- оптимизирует логический план и превращает его в план выполнения;  
- выполняет (интерпретирует) план и возвращает результаты.  

## Поэтапный алгоритм работы планировщика

1) Анализ запроса  
Планировщик проверяет синтаксис и ссылки на объекты в базе

2) Планирование запроса: 
    - поиск подходящего плана в кэше - первым делом планировщик проверяет нет ли уже скомпелированного плана в кэше   
    - поиск оптимального запроса - если плана нет к кэше нет или структура базы была изменена, планировщик искать потимальный план запроса. Составит разные и выберет оптимальный  

## EXPLAIN  

Увидеть план запроса не выплняя его можно с помощью команды  `EXPLAIN`  
```sql
EXPLAIN 
 SELECT * 
   FROM online_store.orders;
```
Результат выполнения:
```
QUERY PLAN
Seq Scan on orders  (cost=0.00..346.67 rows=21167 width=18)
(1 row)
```

# Сборщик статистики в PostgreSQL

Подсистема для сбора и отбражения информации о работе БД. Планировщик использует ее для того, чтобы оценить скорость выполнения запроса, объем данных, количество строк возвращаемых запросом.  
Например, в таблице было 1_000 записей, статистика давно не собиралась, таблица увеличилась до 1_000_000 записей. Без обновленной статистики Планировщик не зная об изменениях может подобрать неоптимальынй план выполнения запроса.  
Сборщик статистики отслеживает, например, общее число строк в каждой таблице или индексе, размеры таблиц или индексов, наиболее часто встречающиеся значения в каждом столбце и ещё множество параметров.  

## Запуск сбора статистики

Для ручного сбора статистики используют команду `ANALYZE`. Планировщик использует статистическую информацию о БД для оценки и построения планов выполнения. Если в таблице было 10_000 строк а стало 1_000_000 то оптимизатор строя запрос на старом плане, в котором еще старое колчиество строк может выбрать неоптимальный план. Чтобы планировщик запроса работал корректно, статистика должна быть актуальной.

Анализировать всю БД:
```sql
ANALYZE;
```

Анализ конкретных таблиц:
```sql
ANALYZE orders, clients, items;
```

Анализ конкретных полей таблицы:
```
ANALYZE orders (order_id, created_at);
```

# Оценка стоимости запроса

**Стоимость запроса** - это абстрактная величина, служащая для сравнения сравнения запросов планировщиком между собой.  

Рассмотрим пример:  
```sql
EXPLAIN 
 SELECT * 
   FROM online_store.orders;
```
Результат выполнения:
```
QUERY PLAN
Seq Scan on orders  (cost=0.00..346.67 rows=21167 width=18)
(1 row)
```
## cost
У стоимости `cost` в результате выполнения команды `EXPLAIN` указано два значения: `cost=0.00..346.67`.
- первое значение - "Стартовая стоимость", т.е. сколько потребуется времени для получения первой строки. У нас это `0.00` секунд.  
- второе значение - "Полная стоимость", зависит от количества возвращаемых данных. В нашем примере - `346.67`.  

Рассмотрим другой пример:
```sql
EXPLAIN 
 SELECT p.user_id, o.*
   FROM online_store.profiles p
   LEFT JOIN online_store.orders o ON o.user_id = p.user_id
  WHERE region = 'Russian Federation';
```
Результат выполнения:
```
QUERY PLAN
Hash Right Join  (cost=3584.61..4043.46 rows=21904 width=26)
Hash Cond: (o.user_id = p.user_id)
->  Seq Scan on orders o  (cost=0.00..346.67 rows=21167 width=18)
->  Hash  (cost=3310.81..3310.81 rows=21904 width=8)
        ->  Seq Scan on profiles p  (cost=0.00..3310.81 rows=21904 width=8) 
                Filter: (region = 'Russian Federation'::text)
(6 rows)
```

Здесь стоит обратить внимание, что мы получаем разную стоимость `cost` на разных строках, которые влияют на общую.  
- стартовая стоимость - `3584.61`  
- полная стоимость - `4043.46`  

# Чтение плана выполнения запроса

Выполним запрос:
```sql
SELECT 'Москва', 
        count(*) 
  FROM clients c 
 WHERE c.city = 'Москва'

UNION ALL

SELECT 'Не Москва', 
       count(*) 
  FROM clients c 
 WHERE c.city != 'Москва';
```

План выполнения:
```
Append **** (cost=15.94..33.30 rows=2 width=40) 
        (actual time=0.130..0.292 rows=2 loops=1)
  ->  Aggregate  (cost=15.94..15.95 rows=1 width=40) 
                 (actual time=0.129..0.130 rows=1 loops=1)
        ->  Seq Scan on clients c  (cost=0.00..15.75 rows=76 width=0) 
                                   (actual time=0.017..0.122 rows=76 loops=1)
                Filter: ((city)::text = 'Москва'::text)
                Rows Removed by Filter: 624
  ->  Aggregate  (cost=17.31..17.32 rows=1 width=40) 
                 (actual time=0.160..0.160 rows=1 loops=1)
        ->  Seq Scan on clients c_1  (cost=0.00..15.75 rows=624 width=0) 
                                     (actual time=0.010..0.129 rows=624 loops=1)
                Filter: ((city)::text <> 'Москва'::text)
                Rows Removed by Filter: 76
Planning Time: 0.188 ms
Execution Time: 0.325 ms
```

План представлен в виде дерева, каждый шаг в нем - узед `->`.  Все узлы, кроме корневого отмечают стрелкой `->`, здесь корневой узел это `Append`. План читается снизу вверх. Каждый узел передает вышестоящему свои результаты. В нашем примере можно выделить:  
- `Seq Scan` - последовательное сканирование    
- `Agregate` - агрегирование данных    
- `Append` - объединение двух результирующих наборов через `UNION ALL`  

Дополнительно может быть указана разная информация, например: 
- У операции сканирования `Seq Scan` мы видим `Filter`. Видно условия фильтрация и количество отсеянных строк `Rows Removed by Filter`  

Стоит также обратить внимание на то, что операции выполняются снизу вверх от дочерних узлов к вышестоящим, так, в нашем примере сначала независимо друг от друга выполяется сканирование `Seq Scan`, затем агрегирование `Agregate` и в самом конце объединение `Append`.  

## Ожидаемый и фактический план выполнения запроса

### Ожидаемый

`EXPLAIN` - запрос не выполняется, затраты ожидаемые.  
```sql
EXPLAIN 
 SELECT COUNT(*) 
   FROM tools_shop.users;
```

### Фактический

`EXPLAIN ANALYZE` - запрос выполняется, возвращает план выполнения. Реальные затраты.  
```sql
EXPLAIN ANALYZE
 SELECT COUNT(*) 
   FROM tools_shop.users;
```

**Важно!** Поскольку `EXPLAIN ANALYZE` сначала выполняет запрос а затем возвращает план его выполнения нужно быть очень аккуратным и не использовать его вместе с `DELETE`, `UPDATE`, `INSERT`.  

Либо используйте транзакции:  
```sql
BEGIN;
EXPLAIN ANALYZE … ;
ROLLBACK; 
```

## Формат плана запроса

### xml, json, yaml

По умолчанию план выполнения запроса возвращается в текстовом варианте, однако можно получить его в формате `xml`, `json`, `yaml`.  

```sql
EXPLAIN (FORMAT json)
 SELECT COUNT(*) 
   FROM tools_shop.users;

EXPLAIN (ANALYZE, FORMAT xml)
 SELECT COUNT(*) 
   FROM tools_shop.users;
```

вывод:
```json
[
  {
    "Plan": {
      "Node Type": "Aggregate",
      "Strategy": "Plain",
      "Partial Mode": "Simple",
      "Parallel Aware": false,
      "Async Capable": false,
      "Startup Cost": 2568.72,
      "Total Cost": 2568.74,
      "Plan Rows": 1,
      "Plan Width": 8,
      "Disabled": false,
      "Plans": [
        {
          "Node Type": "Seq Scan",
          "Parent Relationship": "Outer",
          "Parallel Aware": false,
          "Async Capable": false,
          "Relation Name": "users",
          "Alias": "users",
          "Startup Cost": 0.00,
          "Total Cost": 2275.78,
          "Plan Rows": 117178,
          "Plan Width": 0,
          "Disabled": false
        }
      ]
    }
  }
]
```

### Графическое отображение

Выполнив запрос
```sql
SELECT 'Имя не заполнено' as descr, 
       COUNT(*) AS qty
  FROM tools_shop.users
 WHERE LENGTH(first_name) = 1
 UNION ALL
SELECT 'Имя заполнено', 
       COUNT(*) AS qty 
  FROM tools_shop.users
 WHERE LENGTH(first_name) > 1;
 ```

 Мы  увидим весьма запутанную структуру  
```bash
Gather  (cost=3863.14..3959.53 rows=2 width=40) (actual time=10.088..40.231 rows=2.00 loops=1)
  Workers Planned: 2
  Workers Launched: 2
  Buffers: shared hit=2208
  ->  Parallel Append  (cost=2863.14..2959.33 rows=1 width=40) (actual time=3.186..7.381 rows=0.67 loops=3)
        Buffers: shared hit=2208
        ->  Aggregate  (cost=2959.32..2959.33 rows=1 width=40) (actual time=12.580..12.580 rows=1.00 loops=1)
              Buffers: shared hit=1104
              ->  Seq Scan on users  (cost=0.00..2861.67 rows=39059 width=0) (actual time=0.024..9.351 rows=85249.00 loops=1)
                    Filter: (length(first_name) > 1)
                    Rows Removed by Filter: 31929
                    Buffers: shared hit=1104
        ->  Aggregate  (cost=2863.14..2863.15 rows=1 width=40) (actual time=9.554..9.554 rows=1.00 loops=1)
              Buffers: shared hit=1104
              ->  Seq Scan on users users_1  (cost=0.00..2861.67 rows=586 width=0) (actual time=0.021..8.125 rows=31929.00 loops=1)
                    Filter: (length(first_name) = 1)
                    Rows Removed by Filter: 85249
                    Buffers: shared hit=1104
Planning Time: 0.107 ms
Execution Time: 40.274 ms
```

Однако можно использовать графическое отображение, запустив запрос комбинацией клавиш `Ctrl` + `Shift` + `E` в DBeaver и поулчить план в очень удобном графическом виде.

![alt text](image.png)

Запрос выполняется с использованием параллельного плана:

- На первом уровне два процесса производят последовательное сканирование таблицы `users` с последующей агрегацией

- На втором уровне узел `Append` объединяет результаты от процессов

- На третьем уровне узел `Gather` координирует параллельное выполнение и возвращает финальный результат

Для анализа плана выполнения запроса можно также использовать онлайн-сервисы, например, https://explain.tensor.ru. 

## Показатели в пдане выполнения запроса

Рассмотрим запрос:
```bash
Gather  (cost=6702.27..6894.86 rows=2 width=40) 
        (actual time=97.088..211.292 rows=2 loops=1)
  Workers Planned: 2
  Workers Launched: 2
      ->  Parallel Append  (cost=5702.27..5894.66 rows=1 width=40) 
                         (actual time=32.172..70.201 rows=1 loops=3)
        ->  Aggregate  (cost=5894.64..5894.65 rows=1 width=40) 
                       (actual time=114.078..114.079 rows=1 loops=1)
              ->  Seq Scan on users  (cost=0.00..5699.34 rows=78119 width=0) 
                                     (actual time=0.029..94.106 rows=170498 loops=1)
                    Filter: (length(first_name) > 1)
                    Rows Removed by Filter: 63858
        ->  Aggregate  (cost=5702.27..5702.28 rows=1 width=40) 
                       (actual time=96.506..96.507 rows=1 loops=1)
              ->  Seq Scan on users users_1  
                           (cost=0.00..5699.34 rows=1172 width=0) 
                           (actual time=0.043..88.811 rows=63858 loops=1)
                    Filter: (length(first_name) = 1)
                    Rows Removed by Filter: 170498
Planning Time: 0.183 ms
Execution Time: 211.355 ms
```

Актуально для `EXPLAIN ANALYSE`
```bash
Planning Time: 0.183 ms    -- время планирования и выбора лучше варианта
Execution Time: 211.355 ms -- время выполнения и возврата результата
```


```bash
Gather  (cost=6702.27..6894.86 rows=2 width=40) 
        (actual time=97.088..211.292 rows=2 loops=1)
```

У корневого `Gather` и дочерних `->` в скобках перечисленые показатели: 
- `cost` - стоимость выполнения узла, а т.к. узел корневой, то и всех дочерних узлов учтена в этой стоимомости. Как и ранее, первое число - стоимость получения первой строки, второе число - стоимость получения всего набора. По этому значению можно сравнивать запросы для выбора наилучшего, с минимальнйо стоимостью.    
- `rows` - общее количество строк, ожидаемых в выводе. В нашем примере их две.   
- `width` - это количество байт в каждой строке в выводе.  

Вторые скобки актуальны для `EXPLAIN ANALYSE`:  
- `actual time` - фактическое время получения первой строки и всего набора. Может сильно зависеть от загрузки на сервере.   
- `rows` - количество строк в результирующем наборе. Если колчиество строк в факте сильно отличается от ожидаемого количества, возможно стоит обновить статистику т.к. вероятно она неактуальна.   
- `loops` - количество выполнений узла. В других случая узел может выполняться несколько раз для получения результата.  

Напрмиер:  
```bash
Parallel Append  (cost=5702.27..5894.66 rows=1 width=40) 
                 (actual time=32.172..70.201 rows=1 loops=3)
```
узел выполнялся трижды `loops=3`. Среднее время на итерацию 70, прохода 3, 3 * 70 = 210 мс. 

### Вывод доп. информации

Многословный `VERBOSE` вывод.  
```sql
EXPLAIN (ANALYSE, VERBOSE)
SELECT 'Имя не заполнено' as descr, 
       COUNT(*) AS qty
  FROM tools_shop.users
 WHERE LENGTH(first_name) = 1
 UNION ALL
SELECT 'Имя заполнено', 
       COUNT(*) AS qty 
  FROM tools_shop.users
 WHERE LENGTH(first_name) > 1;
```

Добавив `EXPLAIN (ANALYSE, **VERBOSE**)` получчаем вот такой план выполнения, расширенный.  
```bash
Gather  (cost=3863.14..3959.53 rows=2 width=40) (actual time=15.427..59.715 rows=2.00 loops=1)
  Output: ('Имя заполнено'::text), (count(*))
  Workers Planned: 2
  Workers Launched: 2
  Buffers: shared hit=2208
  ->  Parallel Append  (cost=2863.14..2959.33 rows=1 width=40) (actual time=4.932..12.031 rows=0.67 loops=3)
        Buffers: shared hit=2208
        Worker 0:  actual time=0.001..0.002 rows=0.00 loops=1
        Worker 1:  actual time=0.001..0.002 rows=0.00 loops=1
        ->  Aggregate  (cost=2959.32..2959.33 rows=1 width=40) (actual time=21.294..21.295 rows=1.00 loops=1)
              Output: 'Имя заполнено'::text, count(*)
              Buffers: shared hit=1104
              ->  Seq Scan on tools_shop.users  (cost=0.00..2861.67 rows=39059 width=0) (actual time=0.026..15.908 rows=85249.00 loops=1)
                    Output: users.user_id, users.first_name, users.last_name, users.email, users.created_at
                    Filter: (length(users.first_name) > 1)
                    Rows Removed by Filter: 31929
                    Buffers: shared hit=1104
        ->  Aggregate  (cost=2863.14..2863.15 rows=1 width=40) (actual time=14.790..14.791 rows=1.00 loops=1)
              Output: 'Имя не заполнено'::text, count(*)
              Buffers: shared hit=1104
              ->  Seq Scan on tools_shop.users users_1  (cost=0.00..2861.67 rows=586 width=0) (actual time=0.032..12.771 rows=31929.00 loops=1)
                    Output: users_1.user_id, users_1.first_name, users_1.last_name, users_1.email, users_1.created_at
                    Filter: (length(users_1.first_name) = 1)
                    Rows Removed by Filter: 85249
                    Buffers: shared hit=1104
Query Identifier: -2066355704282925592
Planning Time: 0.209 ms
Execution Time: 59.769 ms
```

Появились записи:  
- `Output` - информация о возвращаемых уздами полях.  
- `Parallel Append` `Worker 0, 1` - информация о параллельных потоках.  

# Операции получения данных

Выполни запрос и взглянем на его план:
```sql
EXPLAIN ANALYZE 
 SELECT 'Имя не заполнено' AS descr, 
         COUNT(*) AS qty 
   FROM tools_shop.users 
  WHERE LENGTH(first_name) = 1 
  UNION ALL 
 SELECT 'Имя заполнено', 
        COUNT(*) 
   FROM tools_shop.users 
  WHERE LENGTH(first_name) > 1;
```

```bash
Gather  (cost=3863.14..3959.53 rows=2 width=40) (actual time=48.958..64.677 rows=2.00 loops=1)
  Workers Planned: 2
  Workers Launched: 2
  Buffers: shared hit=2228
  ->  Parallel Append  (cost=2863.14..2959.33 rows=1 width=40) (actual time=20.211..20.212 rows=0.67 loops=3)
        Buffers: shared hit=2228
        ->  Aggregate  (cost=2959.32..2959.33 rows=1 width=40) (actual time=14.196..14.196 rows=1.00 loops=1)
              Buffers: shared hit=1124
              ->  Seq Scan on users  (cost=0.00..2861.67 rows=39059 width=0) (actual time=0.638..11.005 rows=85249.00 loops=1)
                    Filter: (length(first_name) > 1)
                    Rows Removed by Filter: 31929
                    Buffers: shared hit=1124
        ->  Aggregate  (cost=2863.14..2863.15 rows=1 width=40) (actual time=46.433..46.434 rows=1.00 loops=1)
              Buffers: shared hit=1104
              ->  Seq Scan on users users_1  (cost=0.00..2861.67 rows=586 width=0) (actual time=0.048..44.915 rows=31929.00 loops=1)
                    Filter: (length(first_name) = 1)
                    Rows Removed by Filter: 85249 -- количество отброшеных строк по условию фильтра
                    Buffers: shared hit=1104
Planning:
  Buffers: shared hit=59
Planning Time: 1.661 ms
Execution Time: 64.750 ms
```

Операции получения данных показывают нам как именно СУБД будет читать данные из таблиц:
- `Seq Scan` - последовательное сканирование всей таблицы, например, когда подходящего индекса нет.  
- `Parallel Seq Scan` - то же самое, но с использованием нескольких рабочих процессов (worker processes) для ускорения чтения больших таблиц.   
- `Index Only Scan` - Находит записи в индексе, удовлетворяющие условию. Переходит ("прыгает") к соответствующей строке в таблице (heap) по указателю (TID), чтобы получить остальные данные, которых нет в индексе. СУБД сначала находит в индексе соответствующую условиям строку, после чего читает из таблицы все нужные столбцы. Используется, когда индекс не покрывает все необходимые столбцы.  
- `Index Scan` - Находит записи в индексе. Все нужные для запроса данные уже есть в самом индексе (все столбцы в SELECT, WHERE, JOIN покрыты индексом). Читать всю таблицу смысла нет, все данные для запроса есть в индексе.  

## Примеры

### Seq Scan

Выполним запрос и посмотрим на план выполнения:
```sql
EXPLAIN ANALYZE
 SELECT * 
   FROM tools_shop.users;
```

```bash
Seq Scan on users  (cost=0.00..2275.78 rows=117178 width=44) (actual time=0.065..10.402 rows=117178.00 loops=1)
  Buffers: shared hit=1104
Planning:
  Buffers: shared hit=16
Planning Time: 6.849 ms
Execution Time: 18.705 ms
```

 В таблице индексов нет и мы ожидаемо видим `Seq Scan`, к тому же даже если бы они были, мы бы их не увидели ведь мы выбираем все записи из таблицы.  

В запрос добавим условие
 ```sql
EXPLAIN ANALYZE
 SELECT * 
   FROM tools_shop.users 
  WHERE email = 'Isabella_Nielsen@gmail.com';
 ```

 ```bash
Seq Scan on users  (cost=0.00..2568.73 rows=1 width=44) (actual time=3.066..8.742 rows=1.00 loops=1)
  Filter: (email = 'Isabella_Nielsen@gmail.com'::text)
  Rows Removed by Filter: 117177
  Buffers: shared hit=1104
Planning:
  Buffers: shared hit=8
Planning Time: 0.101 ms
Execution Time: 8.767 ms
 ```

И вновь `Seq Scan` ведь в таблице нет индексов.  Зато в плане появился нвоый атрибут, показывающий сколько строк мы отсеяли для получения резльтирующего набора - `Rows Removed By Filter`.  
```bash
Filter: (email = 'Isabella_Nielsen@gmail.com'::text)
  Rows Removed by Filter: 117177 -- фильтр отбросил 117177 строку
```

### Index Scan

Добавим покрывающий индекс в наш запрос и взглянем на план выполнения:
```sql
CREATE INDEX user_email_idx ON tools_shop.users(email) INCLUDE (user_id);
```

```sql
EXPLAIN ANALYZE
 SELECT * 
   FROM tools_shop.users 
  WHERE email = 'Isabella_Nielsen@gmail.com';
```

```bash
Index Scan using user_email_idx on users  (cost=0.42..3.44 rows=1 width=44) (actual time=0.083..0.084 rows=1.00 loops=1)
  Index Cond: (email = 'Isabella_Nielsen@gmail.com'::text)
  Index Searches: 1
  Buffers: shared hit=1 read=3
Planning:
  Buffers: shared hit=22 read=1
Planning Time: 1.789 ms
Execution Time: 0.100 ms
```

Теперь мы видим `Index Scan` а это значит, что СУБД сперва ищет по индексу а затем смотрит в таблицу чтобы вернуть остальные поля принадлежащие данному индексу по строке. 
`Index Cond` показывает условие, по котормоу выбирались строки в индексе и в отличии от `Filter` в `Sec Sqan` он отрабатывает до того как субд начинает прсоматривать таблицу. Т.е. `Filter` в `Sec Sqan` читаем слишком много лишних данных.

### Index Only Scan

Теперь вернем только id пользователя. напоминаю, что индекс покрывающий и все id ест ьв самом индексе, т.е. в таблицу смотреть вообще не нужно:
```sql
SELECT user_id 
  FROM tools_shop.users 
 WHERE email = 'Isabella_Nielsen@gmail.com'
```

```bash
Index Only Scan using user_email_idx on users  (cost=0.42..3.44 rows=1 width=4) (actual time=0.313..0.318 rows=1.00 loops=1)
  Index Cond: (email = 'Isabella_Nielsen@gmail.com'::text)
  Heap Fetches: 0
  Index Searches: 1
  Buffers: shared hit=4
Planning Time: 0.091 ms
Execution Time: 0.336 ms
```

В плане выполнения видим `Index Only Scan` это значит, что в результирующий набор возвращены лишь данные из самого индекса и в таблицу субд даже не ходила. 

| Показатель | Seq Scan | Index Scan | Index Only Scan |
|------------|----------|------------|-----------------|
| Время выполнения | 8.767 ms | 0.100 ms | 0.336 ms |
| Прочитано данных | 8.6 MB | 32 KB | 32 KB |
| Сканирование | Вся таблица | Индекс + нужные строки | Только индекс |

**Критерий выбора стратегии (правило 30%)**:  
- `< 30% строк` — использовать индекс (Index Scan или Index Only Scan). PostgreSQL эффективно отфильтрует данные до обращения к таблице.  
- `> 40% строк` — выгоднее Seq Scan. Затраты на массовый доступ к индексу + многократные чтения из таблицы превышают стоимость полного сканирования.  
- `30-40%` — серая зона. Оптимизатор PostgreSQL анализирует статистику и выбирает стратегию на основе стоимости операций.

### Bitmap Index Scan

В случаях, когда условию удовлетворяет значительное, но всё же не преобладающее количество строк таблицы (например, 10-30%), прямое последовательное сканирование `Seq Scan` становится избыточным, а множественные точечные чтения через обычный `Index Scan` — неэффективными. Для этого сценария PostgreSQL использует гибридную стратегию — `Bitmap Index Scan`.  

При `Bitmap Index Scan` PostgreSQL сканирует индекс и строит битовую карту `bitmap` — структуру, где каждый бит соответствует одной странице таблицы. Бит устанавливается в 1, если индекс указывает, что на этой странице могут быть подходящие данные. Затем `Bitmap Heap Scan` читает только отмеченные страницы, и для каждой строки на них выполняется повторная проверка условия `Recheck Cond`, поскольку индекс мог указать на страницу, но не на конкретную строку.

При малом количестве возвращаемых строк (обычно <1% от таблицы) накладные расходы на построение и обработку битовой карты могут превысить выгоду от её использования. В таких случаях прямой доступ через `Index Scan` будет эффективнее.

Создадим еще один индекс:
```sql
CREATE INDEX user_created_at_idx ON tools_shop.users(created_at);
```

Выполним запрос:
```sql
EXPLAIN ANALYZE
 SELECT user_id  
   FROM tools_shop.users 
  WHERE created_at ='2020-01-21'
    AND email != 'ReemWeber1976@gmail.com';
```

Взглянем на план:
```bash
Bitmap Heap Scan on users  (cost=2.24..82.14 rows=58 width=4) (actual time=0.259..0.334 rows=80.00 loops=1)
  Recheck Cond: (created_at = '2020-01-21'::date)
  Filter: (email <> 'ReemWeber1976@gmail.com'::text)
  Rows Removed by Filter: 1
  Heap Blocks: exact=77
  Buffers: shared hit=77 read=2
  ->  Bitmap Index Scan on user_created_at_idx  (cost=0.00..2.23 rows=58 width=0) (actual time=0.045..0.045 rows=81.00 loops=1)
        Index Cond: (created_at = '2020-01-21'::date)
        Index Searches: 1
        Buffers: shared read=2
Planning:
  Buffers: shared hit=25 read=2
Planning Time: 2.134 ms
Execution Time: 0.670 ms
```

1) `Bitmap Index Scan` (нижний узел) использует индекс `user_created_at_idx` для поиска всех записей с `created_at = '2020-01-21'`. Результатом становится битовая карта, отмечающая 77 страниц таблицы, где могут находиться подходящие строки.  
2) `Bitmap Heap Scan` (верхний узел) читает только эти 77 страниц (вместо всей таблицы). Для каждой считанной строки последовательно проверяется:  
* `Recheck Cond` — повторная проверка условия по `created_at` (поскольку индекс указывал только на страницу, а не на конкретную строку)    
* `Filter` — дополнительное условие `email <> '...'`, которое отсеяло 1 строку   

Оптимизатор сознательно отказался от использования второго индекса по email, так как фильтрация по этому полю эффективно выполняется уже на этапе чтения данных из таблицы (Bitmap Heap Scan).

# Операции обработки данных

## Фильтрация и сортировка

Речь пойдет о`limit` и `sort`.  

### limit

Встречается в плане выполнения запроса если в нем присуствует `limit` или `offset`.  

`limit` остановит выполнение запроса когда получит от дочерней операции необходимое количество строк. Если в запросе есть `offset` то в `limit` дополнительно передадутся все строки, на которые нужно сместить выбор + строки для отображения. И в узле `limit` лишние строки будут отсечены. 

```sql
EXPLAIN ANALYZE
 SELECT * 
   FROM tools_shop.users 
  ORDER BY created_at  
  LIMIT 10
 OFFSET 1000;
 ```

 ```bash
Limit  (cost=30.76..31.06 rows=10 width=44) (actual time=0.628..0.634 rows=10.00 loops=1)
  Buffers: shared hit=1007
  ->  Index Scan using user_created_at_idx on users  (cost=0.29..3569.93 rows=117178 width=44) (actual time=0.019..0.591 rows=1010.00 loops=1)
        Index Searches: 1
        Buffers: shared hit=1007
Planning Time: 0.134 ms
Execution Time: 0.649 ms
 ```

Из интересного:
- `Index Scan` - сортировка по полю с индексом `created_at`. `ORDER BY created_at`  
- ожидаемая стоимость и количество строк довольно высокие: `cost=0.29..3569.93`, `rows=117178`   
- фактическое количество возвращаемых строк в этом узле: `rows=1010.00` 1000 это `offset` + 10 `limit`  
- операция `limit` вовремя останавливает `Index Scan` получив необходимое количество строк  
- `sort` не нужна, т.к. сортировка производится по столбцу с индексом  

### sort

Встречается в запросах с `ORDER BY`, или в запросах есть условия, которыем потребуется предварительная сортировка `GROUP BY` или `UNION`.

Выполним тот же запрос но с сортировкой по столбцу без индекса.  

```sql
EXPLAIN ANALYZE
 SELECT * 
   FROM tools_shop.users 
  ORDER BY user_id    
  LIMIT 10
 OFFSET 1000;
```

```bash
Limit  (cost=6691.46..6692.60 rows=10 width=44) (actual time=41.142..46.389 rows=10.00 loops=1)
  Buffers: shared hit=1141
  ->  Gather Merge  (cost=6577.49..19932.33 rows=117178 width=44) (actual time=40.895..46.345 rows=1010.00 loops=1)
        Workers Planned: 1
        Workers Launched: 1
        Buffers: shared hit=1141
        ->  Sort  (cost=5577.48..5749.80 rows=68928 width=44) (actual time=11.198..11.253 rows=505.00 loops=2)
              Sort Key: user_id
              Sort Method: top-N heapsort  Memory: 195kB
              Buffers: shared hit=1141
              Worker 0:  Sort Method: quicksort  Memory: 25kB
              ->  Parallel Seq Scan on users  (cost=0.00..1793.28 rows=68928 width=44) (actual time=0.007..4.876 rows=58589.00 loops=2)
                    Buffers: shared hit=1104
Planning:
  Buffers: shared hit=4
Planning Time: 0.349 ms
Execution Time: 46.474 ms
```

Рассмотрим:  
стоимость запроса выросла в 100 раз! с `0.634` до `46.389`. Работы было много  
- `Parallel Seq Scan on users` - всю таблицу пришлось сортировать в параллельном режиме последовательного сканирования  
- выбор записей `rows=505 * loops=2`  
- объединение записей в узле `Gather Merge`  
- и только в самом конце `Gather Merge` передаст результаты в `Limit` чтобы вернуть 10 и отбросить 1000 щаписей.  

Как видно, что самая затратная операция `sort`. По этому во время оптимизации нужно старатсья избавлятсья от сортировки в плане запроса добавляя индексы и переписывая запрос.

## Агрегация

Встречается если в запросе есть агрегации или оконные функции.

### WindowAgg

Оконная функция и ее влияние на производительность.  

```sql
EXPLAIN ANALYZE
SELECT *, 
       row_number() OVER(ORDER BY user_id), 
       count(*) OVER(PARTITION BY last_name)
  FROM tools_shop.users;
```

```bash
WindowAgg  (cost=24057.25..26107.84 rows=117178 width=59) (actual time=174.763..205.619 rows=117178.00 loops=1)
  Window: w2 AS (ORDER BY user_id ROWS UNBOUNDED PRECEDING)
  Storage: Memory  Maximum Storage: 17kB
  Buffers: shared hit=1104
  ->  Sort  (cost=24057.23..24350.17 rows=117178 width=51) (actual time=174.748..187.719 rows=117178.00 loops=1)
        Sort Key: user_id
        Sort Method: quicksort  Memory: 11292kB
        Buffers: shared hit=1104
        ->  WindowAgg  (cost=12165.89..14191.81 rows=117178 width=51) (actual time=113.406..150.950 rows=117178.00 loops=1)
              Window: w1 AS (PARTITION BY last_name)
              Storage: Memory  Maximum Storage: 228kB
              Buffers: shared hit=1104
              ->  Sort  (cost=12141.20..12434.14 rows=117178 width=43) (actual time=113.122..125.274 rows=117178.00 loops=1)
                    Sort Key: last_name
                    Sort Method: quicksort  Memory: 10377kB
                    Buffers: shared hit=1104
                    ->  Seq Scan on users  (cost=0.00..2275.78 rows=117178 width=43) (actual time=0.024..12.549 rows=117178.00 loops=1)
                          Buffers: shared hit=1104
Planning Time: 0.163 ms
Execution Time: 209.444 ms
```

В запросе есть две оконные функции, дял каждоый из них была произведена сортировка таблицы целиком `sort`.   
Также у оконных функций есть `OVER()` и в случае если бы там были одинаковые параметры выполнять операцию дважды не потребовалось бы, а если бы в `OVER()` использовалось бы поле с индексом, то дополнительная сортировка бы вообще не понадобилась.    

*При работе с оконными функциями избегайте сортировки и секционирования по колонкам без индексов. Если без этого не обойтись, используйте для всех оконных функций одни и те же поля — так PostgreSQL выполнит сортировку всего один раз. *

Например, как выглядит план с оконными функциями и одинаковыми `OVER()` или `OVER()` с индексом

```sql
EXPLAIN ANALYZE
SELECT *, 
       row_number() OVER(ORDER BY user_id), 
       count(*) OVER(ORDER BY user_id)
  FROM tools_shop.users;
```

```bash
WindowAgg  (cost=12141.22..14484.76 rows=117178 width=59) (actual time=30.294..73.991 rows=117178.00 loops=1)
  Window: w1 AS (ORDER BY user_id)
  Storage: Memory  Maximum Storage: 17kB
  Buffers: shared hit=1104
  ->  Sort  (cost=12141.20..12434.14 rows=117178 width=43) (actual time=30.260..42.637 rows=117178.00 loops=1)
        Sort Key: user_id
        Sort Method: quicksort  Memory: 10377kB
        Buffers: shared hit=1104
        ->  Seq Scan on users  (cost=0.00..2275.78 rows=117178 width=43) (actual time=0.025..5.733 rows=117178.00 loops=1)
              Buffers: shared hit=1104
Planning Time: 0.148 ms
Execution Time: 76.942 ms
```

С индексом:
```sql
EXPLAIN ANALYZE
SELECT *, 
       row_number() OVER(ORDER BY email), 
       count(*) OVER(ORDER BY email)
  FROM tools_shop.users;
```

```bash
WindowAgg  (cost=0.47..6531.06 rows=117178 width=59) (actual time=0.036..96.334 rows=117178.00 loops=1)
  Window: w1 AS (ORDER BY email)
  Storage: Memory  Maximum Storage: 17kB
  Buffers: shared hit=117775
  ->  Index Scan using user_email_idx on users  (cost=0.42..4480.44 rows=117178 width=43) (actual time=0.024..43.755 rows=117178.00 loops=1)
        Index Searches: 1
        Buffers: shared hit=117775
Planning Time: 0.109 ms
Execution Time: 99.662 ms
```

### GroupAggregate

Агрегация по ключу, колонкам в выражении `GROUP BY`.  

```sql
EXPLAIN ANALYZE
 SELECT email, 
        count(*)  
   FROM tools_shop.users 
  GROUP BY email;
```

```bash
GroupAggregate  (cost=0.42..6273.37 rows=108539 width=32) 
                (actual time=0.036..73.706 rows=112395 loops=1)
  Group Key: email
  ->  Index Only Scan using user_email_idx on users  
                     (cost=0.42..4602.09 rows=117178 width=24) 
                     (actual time=0.019..18.380 rows=117178 loops=1)
        Heap Fetches: 0
Planning Time: 0.700 ms
Execution Time: 77.636 ms
```

- `Group Key` покажет по каким полям сагрегированы данные `Group Key: email`  
- учитывая, что агрегация произведена по полю с индексом `user_email_idx` мы избежали дополнительной сортировки и еще одного узла `-> sort`  

*Отсюда следует, что как и в случае с оконными фнукциями агрегацию лучше выполнять по полям с индексом*

### HashAggregate

Сортировка с использованием хеш-таблицы обычно используется когда нужно сортировать большой объем неотсортированных данных.  

Хеш-таблица — это структура данных, которая хранит объекты, распределяя их по ячейкам-«корзинам» с помощью хеш-функции. Эта функция вычисляет для каждого объекта число (хеш), определяющее, в какую корзину его поместить. Когда нужно найти объект, хеш-функция быстро указывает на нужную корзину.

В планах запросов PostgreSQL операция `Hash` как раз строит такую хеш-таблицу. 

```sql
EXPLAIN ANALYZE 
 SELECT DISTINCT *
   FROM tools_shop.users ;
```

```bash
HashAggregate  (cost=12087.56..12776.84 rows=68928 width=44) 
               (actual time=397.856..472.822 rows=117178 loops=1)
  Group Key: user_id, first_name, last_name, email, created_at
  Batches: 5  Memory Usage: 8241kB  Disk Usage: 4864kB
  ->  Gather  (cost=3643.88..11225.96 rows=68928 width=44) 
              (actual time=113.848..231.695 rows=117178 loops=1)
        Workers Planned: 1
        Workers Launched: 1
        ->  HashAggregate  (cost=2643.88..3333.16 rows=68928 width=44) 
                           (actual time=68.095..120.050 rows=58589 loops=2)
              Group Key: user_id, first_name, last_name, email, created_at
              Batches: 5  Memory Usage: 8241kB  Disk Usage: 4504kB
              Worker 0:  Batches: 1  Memory Usage: 3857kB
              ->  Parallel Seq Scan on users  
                                    (cost=0.00..1782.28 rows=68928 width=44) 
                                    (actual time=0.015..8.664 rows=58589 loops=2)
Planning Time: 0.166 ms
Execution Time: 482.902 ms
```

- Основная операция — HashAggregate с группировкой по 5 колонкам: user_id, first_name, last_name, email, created_at. Обработано строк: 117,178  
- Параллельное выполнение: Использован 1 дополнительный воркер (всего 2 потока) Каждый поток выполнил `Parallel Seq Scan`. Обработано по ~58,589 строк в каждом потоке - 
- Причина выбора `HashAggregate`: Группировка по 5 неиндексированным колонкам, Сортировка для `GroupAggregate` была бы более затратной. PostgreSQL выбрал хеширование как оптимальный метод  
- `DISTINCT` по множеству колонок требует значительных ресурсов. Следует использовать только при реальной необходимости  

# Операции соединения таблиц

При использовании `join` в плане запроса могут встречаться: `Nested Loop`, `Hash Join`, `Merge Join`. В основе каждой лежит свой алгоритм соединения таблиц, по этому скорость и стоимость могут значительно отличаться. В идеале, если СУБД выбрала не самый оптимальный вариант, наша задача переписать запрос так чтобы запрос отрабатывал эффективнее.  

## Nested Loop

`Nested Loop` - соединяет таблицы вложенными циклами. Алгоритм следующий - из первой таблице берется строка, затем полным сканированием или индексом выбираются все отвечающие условию строки второй таблицы. Затем берется вторая стркоа первой таблицы и т.д.  
В первой цикле перебираются строки первой таблицы, а во вложенном строки второй таблицы. Первая таблица чиается один раз, а вторая столько раз, сколько строк в первой таблице. Прчием СУБД сама решает, какая таблица будет первой а какая второй. 

**Когда и спользовать**

`Nested Loop Join`: **когда использовать**

| Ситуация | Почему подходит Nested Loop |
|----------|-----------------------------|
| **Маленькие объёмы данных** | Время работы растёт линейно при небольших таблицах |
| **Запрос с `LIMIT`** | Возвращает первые результаты сразу, не обрабатывая всё |
| **Проверка `EXISTS`/`NOT EXISTS`** | Достаточно найти хотя бы одно совпадение/несовпадение |
| **Сложные условия соединения** (> , <, `BETWEEN`, функции) | Только Nested Loop поддерживает не-равенства |
| **Нужна минимальная задержка** | Начинает выдавать данные немедленно |
| **Есть индекс по внутренней таблице** | Поиск по индексу вместо полного сканирования |

`Nested Loop Join`: **Когда НЕ использовать**

| Ситуация | Проблема |
|----------|----------|
| **Большие таблицы без фильтрации** | Время работы O(n×m) — неприемлемо долго |
| **Нет индекса на столбце соединения** | Каждый раз полное сканирование внутренней таблицы |
| **Требуется полная обработка данных** | Hash/Merge Join масштабируются лучше |

Ключевые индикаторы для выбора
✅ **Можно использовать:** Маленькая внешняя таблица + индекс на внутренней  
❌ **Избегать:** Большие объёмы + отсутствие индексов

Рассмотрим пример:
```sql
EXPLAIN ANALYZE 
 SELECT *
   FROM orders o
   JOIN coupons c ON o.order_sum > c.min_sum;
```

```bash
Nested Loop  (cost=0.00..4380.63 rows=96667 width=273) 
             (actual time=0.055..1.974 rows=2829 loops=1)
  Join Filter: (o.order_sum > c.min_sum)
  Rows Removed by Join Filter: 1171
  ->  Seq Scan on orders o  (cost=0.00..17.00 rows=1000 width=23) 
                            (actual time=0.028..0.126 rows=1000 loops=1)
  ->  Materialize  (cost=0.00..14.35 rows=290 width=250) 
                   (actual time=0.000..0.000 rows=4 loops=1000)
        ->  Seq Scan on coupons c  
                     (cost=0.00..12.90 rows=290 width=250) 
                     (actual time=0.013..0.014 rows=4 loops=1)
Planning Time: 0.271 ms
Execution Time: 2.096 ms
```

1) ```Join Filter: (o.order_sum > c.min_sum)``` соединение использует не равенство `=` а `>`, так гарантировано будут использоваться вложенные циклы  
2) `Materialize` прочитана `Seq Scan` а значит и все ее дочерние узлы 1000 раз `loops=1000`, в том числе таблица `coupons` c `loops=1` - таблица `coupons` сканируется ОДИН РАЗ целиком с диска. Materialize сохраняет `coupons` в памяти и читает ее 1000 раз но не с диска а из памяти
3) `orders` `Seq Scan` была прочитана один раз `loops=1`
 
## Hash Join

Объединяет таблицы при помощи hash-таблицы. СУБД строит хеш таблицу, обычно для той, что поменьше. 
Затем `hash join` для каждой строки второй таблицы расчитывает hash, затем с помощью hash-таблицы отбираются строки, удовлетворяющие условию соединения.    

Накладные расходы больше чем у `nested loop` т.к. hash-таблица хранится в памяти. Работает только по равенству атрибутов, даже для поиска одной строки поналобится строить хеш-таблицу. Из-за чего имеет смысл использовать только на больших объемах данных. Главное преимуществе это быстрое соединение неотсортированных наборов.  

```sql
EXPLAIN ANALYZE
SELECT *
  FROM orders o
  JOIN clients c ON c.id_client = o.id_client

```

```bash
Hash Join  (cost=29.50..64.36 rows=1000 width=290) 
           (actual time=0.606..1.907 rows=1000 loops=1)
  Hash Cond: (c.id_client = o.id_client)
  ->  Seq Scan on clients c  (cost=0.00..21.08 rows=1008 width=267) 
                             (actual time=0.026..0.200 rows=1008 loops=1)
  ->  Hash  (cost=17.00..17.00 rows=1000 width=23) 
            (actual time=0.559..0.560 rows=1000 loops=1)
        Buckets: 1024  Batches: 1  Memory Usage: 63kB
        ->  Seq Scan on orders o  (cost=0.00..17.00 rows=1000 width=23) 
                                  (actual time=0.020..0.198 rows=1000 loops=1)
Planning Time: 2.626 ms
Execution Time: 2.019 ms
```

1) Построение хеш-таблицы `Hash`:  
- Сначала выполняется полное сканирование таблицы orders `Seq Scan`.  
- Данные orders хешируются и помещаются в хеш-таблицу операция `Hash`.  
- Хеш-таблица построена за один проход `Batches = 1`, что означает, что все данные поместились в память. Если бы памяти не хватило, процесс был бы разбит на несколько пакетов.  

2) Соединение с таблицей `clients` `Hash Join`:  
- Выполняется полное сканирование таблицы `clients` `Seq Scan`.  
- Для каждой строки `clients` вычисляется хеш, который указывает на соответствующую "корзину" в хеш-таблице `orders`.  
- СУБД проверяет строки из найденной корзины на соответствие условиям соединения.  

3) Результат:  
- Все подходящие строки возвращаются клиенту, так как `Hash Join` является корневым узлом плана выполнения.  

## Merge Join

`Merge Join` работает как параллельное движение по двум отсортированным таблицам. Указатели начинают с первых строк: при совпадении ключей строка попадает в результат, и указатель второй таблицы двигается дальше. Если совпадения нет — смещается указатель первой таблицы. Так происходит последовательное сравнение всех записей.

`Merge Join` эффективен при работе с данными, уже отсортированными по ключу соединения — как правило, благодаря индексам, которые хранят данные в упорядоченном виде. Этот метод экономичен по памяти, сохраняет порядок сортировки в результате (что полезно для каскадных соединений) и часто используется при объединении больших наборов данных.

PostgreSQL может выбрать этот алгоритм даже для неотсортированных данных, если решит, что предварительная сортировка (через операцию `Sort`) будет выгоднее, чем, например, `Hash Join`. Это характерно для больших таблиц или случаев, где важен порядок результата.  

Для принудительного применения `Merge Join` в PostgreSQL достаточно отсортировать данные по ключу соединения. В учебном примере для этого был добавлен `ORDER BY` в подзапросы, хотя на практике такая явная сортировка обычно не требуется.

На примере того же запроса, что использовался для `Hash Join`, добавление двух операторов `ORDER BY` привело к увеличению стоимости и времени выполнения запроса — что ожидаемо, поскольку сортировка является ресурсоёмкой операцией. Этот пример наглядно показывает компромисс: `Merge Join` эффективен при наличии отсортированных данных, но если сортировка отсутствует, её выполнение может существенно увеличить общие затраты на выполнение запроса.

```sql
EXPLAIN ANALYZE
SELECT c.*
  FROM (SELECT * 
          FROM orders 
         ORDER BY id_client) o
  JOIN (SELECT * 
          FROM clients 
         ORDER BY id_client) c on c.id_client = o.id_client

```

```bash
Merge Join  (cost=138.19..180.81 rows=1000 width=267) 
            (actual time=1.569..3.170 rows=1000 loops=1)
  Merge Cond: (clients.id_client = orders.id_client)
  ->  Sort  (cost=71.37..73.89 rows=1008 width=267) 
            (actual time=0.547..0.687 rows=1008 loops=1)
        Sort Key: clients.id_client
        Sort Method: quicksort  Memory: 118kB
        ->  Seq Scan on clients  (cost=0.00..21.08 rows=1008 width=267) 
                                 (actual time=0.027..0.205 rows=1008 loops=1)
  ->  Materialize  (cost=66.83..81.83 rows=1000 width=4) 
                   (actual time=1.014..1.480 rows=1000 loops=1)
        ->  Sort  (cost=66.83..69.33 rows=1000 width=32) 
                  (actual time=1.008..1.179 rows=1000 loops=1)
              Sort Key: orders.id_client
              Sort Method: quicksort  Memory: 71kB
              ->  Seq Scan on orders  
                           (cost=0.00..17.00 rows=1000 width=32) 
                           (actual time=0.033..0.451 rows=1000 loops=1)
Planning Time: 0.313 ms
Execution Time: 3.397 ms
```

1) Подготовка данных: Обе таблицы были предварительно отсортированы, поскольку данные не были упорядочены по ключу соединения:  
- clients: 1008 строк отсортированы quicksort (118 kB памяти)  
- orders: 1000 строк отсортированы quicksort (71 kB памяти), затем материализованы  

2) Соединение: `Merge Join` эффективно объединил отсортированные наборы, получив 1000 строк результата.